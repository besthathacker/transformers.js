<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>PetGPT Ultimate Offline + Chunked GPT-2</title>
<style>
  body { font-family: Arial, sans-serif; background: #1e1e1e; color: white; margin: 0; padding: 0; display: flex; flex-direction: column; height: 100vh; }
  header, footer { background: #007acc; padding: 16px; text-align: center; font-size: 20px; }
  #chat { flex: 1; overflow-y: auto; padding: 10px; background: #2b2b2b; }
  .message { margin: 6px 0; padding: 8px; border-radius: 6px; max-width: 75%; word-wrap: break-word; }
  .user { background: #3a3a3a; align-self: flex-end; }
  .bot { background: #007acc; align-self: flex-start; }
  #controls { display: flex; padding: 10px; background: #111; border-top: 1px solid #444; }
  #userInput { flex: 1; padding: 8px; border: none; border-radius: 4px; background: #333; color: #eee; }
  button { margin-left: 6px; padding: 8px 12px; border: none; border-radius: 4px; background: #007acc; color: #fff; cursor: pointer; }
  #adminPanel { display: none; background: #333; padding: 10px; border-top: 2px solid #007acc; }
  #adminPanel h4, #adminPanel label { margin: 6px 0; }
</style>
</head>
<body>
<header>🐾 PetGPT Ultimate Offline + Chunked GPT-2</header>

<div id="chat"></div>

<div id="controls">
  <input id="userInput" placeholder="Type your message..." autocomplete="off" />
  <button id="sendBtn">Send</button>
  <button id="resetBtn">Reset Memory</button>
  <button id="voiceBtn">🎤 Voice Chat</button>
</div>

<div id="adminPanel">
  <h4>Admin Panel (type “cheeto”)</h4>
  <label>Background Color: <input type="color" id="bgPicker" /></label>
</div>

<footer>© PetGPT Ultimate</footer>

<script src="https://cdn.jsdelivr.net/npm/@xenova/transformers@2.5.0/dist/transformers.min.js"></script>
<script>
(async () => {
  // URLs for each chunk (21 parts)
  const chunkUrls = [];
  for (let i = 1; i <= 21; i++) {
    chunkUrls.push(`files/gpt2/model.part${i}.bin`);
  }
  const modelConfigUrl = 'files/gpt2/model.json';

  // UI elements
  const chat = document.getElementById('chat');
  const userInput = document.getElementById('userInput');
  const sendBtn = document.getElementById('sendBtn');
  const resetBtn = document.getElementById('resetBtn');
  const voiceBtn = document.getElementById('voiceBtn');
  const adminPanel = document.getElementById('adminPanel');
  const bgPicker = document.getElementById('bgPicker');

  // Memory storage
  let memory = JSON.parse(localStorage.getItem('petgpt-memory') || '{}');

  // Append message helper
  function append(msg, cls) {
    const d = document.createElement('div');
    d.className = 'message ' + cls;
    d.textContent = msg;
    chat.appendChild(d);
    chat.scrollTop = chat.scrollHeight;
  }

  function saveMem() {
    localStorage.setItem('petgpt-memory', JSON.stringify(memory));
  }

  // Fetch and merge all binary chunks
  async function fetchChunks(urls) {
    const buffers = await Promise.all(urls.map(u => fetch(u).then(r => r.arrayBuffer())));
    const totalLength = buffers.reduce((acc, b) => acc + b.byteLength, 0);
    const merged = new Uint8Array(totalLength);
    let offset = 0;
    for (const buffer of buffers) {
      merged.set(new Uint8Array(buffer), offset);
      offset += buffer.byteLength;
    }
    return merged.buffer;
  }

  // Load model.json config
  async function fetchJson(url) {
    const res = await fetch(url);
    return await res.json();
  }

  // Setup transformers environment to allow local buffers
  window.transformers.env.allowLocalModels = true;

  // Load tokenizer and model from merged buffer and config
  let tokenizer, model;
  let gptReady = false;

  append("Loading GPT-2 model (chunked)... Please wait.", "bot");

  try {
    const modelConfig = await fetchJson(modelConfigUrl);
    const modelBuffer = await fetchChunks(chunkUrls);

    tokenizer = await window.transformers.AutoTokenizer.fromPretrained("gpt2");

    model = await window.transformers.AutoModelForCausalLM.fromPretrained(null, {
      config: modelConfig,
      weights: modelBuffer,
    });

    gptReady = true;
    append("GPT-2 model loaded successfully! Test worked!", "bot");
  } catch (e) {
    append("Failed to load GPT-2 model. Falling back to simple dictionary.", "bot");
    console.error(e);
  }

  // Fallback simple dictionary
  const fallbackModel = {
    hello: "Hi there! How can I help you today?",
    bye: "Goodbye! Have a great day!",
    // add more as you want
  };

  // Generate reply with GPT-2 or fallback
  async function getReply(text) {
    const t = text.toLowerCase();

    // teach command
    if (t.startsWith('remember:')) {
      const [k, v] = t.slice(9).split('=').map(s => s.trim());
      if (k && v) {
        memory[k] = v;
        saveMem();
        return `Got it! I'll remember ${k} = ${v}`;
      }
      return `Use: remember:key=value`;
    }

    // recall from memory
    for (let k in memory) {
      if (t.includes(k.toLowerCase())) return `You told me ${k} = ${memory[k]}`;
    }

    // admin unlock
    if (t.includes('cheeto')) {
      adminPanel.style.display = 'block';
      return "Admin unlocked!";
    }

    if (gptReady) {
      try {
        const encoded = await tokenizer.encode(text);
        const output = await model.generate(encoded.inputIds, {
          max_new_tokens: 50,
          do_sample: true,
          temperature: 0.7,
          top_p: 0.9,
        });
        const decoded = await tokenizer.decode(output[0]);
        let reply = decoded.replace(text, '').trim();
        if (!reply) reply = "Hmm, I don't know what to say.";
        return reply;
      } catch (e) {
        console.error("GPT-2 generation error:", e);
      }
    }

    // fallback
    for (const key in fallbackModel) {
      if (t.includes(key)) return fallbackModel[key];
    }

    return "Sorry, I don't understand.";
  }

  // Send message handler
  async function sendMessage() {
    const txt = userInput.value.trim();
    if (!txt) return;
    append("You: " + txt, 'user');
    userInput.value = '';
    userInput.disabled = true;
    sendBtn.disabled = true;
    try {
      const reply = await getReply(txt);
      append("PetGPT: " + reply, 'bot');
    } catch {
      append("PetGPT: Sorry, an error occurred.", 'bot');
    } finally {
      userInput.disabled = false;
      sendBtn.disabled = false;
      userInput.focus();
    }
  }

  sendBtn.onclick = sendMessage;
  userInput.addEventListener('keydown', e => {
    if (e.key === 'Enter') {
      e.preventDefault();
      sendMessage();
    }
  });

  // Reset memory/chat
  resetBtn.onclick = () => {
    if (confirm("Clear memory and chat?")) {
      localStorage.clear();
      memory = {};
      chat.innerHTML = '';
      append("Memory cleared.", "bot");
    }
  };

  // Admin panel color picker
  bgPicker.oninput = e => {
    document.body.style.background = e.target.value;
  };

  // Voice chat setup
  let recognition, recognizing = false;
  if (window.SpeechRecognition || window.webkitSpeechRecognition) {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SR();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.continuous = false;
    recognition.onstart = () => { recognizing = true; voiceBtn.textContent = '🛑 Stop'; };
    recognition.onend = () => { recognizing = false; voiceBtn.textContent = '🎤 Voice Chat'; };
    recognition.onerror = () => { recognizing = false; voiceBtn.textContent = '🎤 Voice Chat'; };
    recognition.onresult = e => {
      const t = e.results[0][0].transcript;
      userInput.value = t;
      sendMessage();
    };
  }
  voiceBtn.onclick = () => {
    if (!recognition) return alert('SpeechRecognition not supported');
    recognizing ? recognition.stop() : recognition.start();
  };

  userInput.focus();
})();
</script>
</body>
</html>
